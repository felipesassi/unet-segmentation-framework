{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os.path\n",
    "\n",
    "path = os.path.dirname(os.getcwd())\n",
    "sys.path.append(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.unet_2d import UNet2D\n",
    "from utils.metrics import dice_metric\n",
    "from utils.loss import soft_dice_loss\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from tqdm.notebook import tqdm_notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MRI_Dataloader(Dataset):\n",
    "    def __init__(self, files):\n",
    "        self.data = files\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.data.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x_dir = path + '/data/X/{}.npy' .format(self.data[\"X\"].values[idx])\n",
    "        y_dir = path + '/data/Y/{}.npy' .format(self.data[\"Y\"].values[idx])\n",
    "        x = np.load(x_dir)\n",
    "        y = np.load(y_dir)\n",
    "        y = y[0] + y[1] + y[2]\n",
    "        y[y >= 1] = 1\n",
    "        y = (y).astype(np.uint8)\n",
    "        return torch.tensor(x).unsqueeze(dim = 0).float(), torch.tensor(y).unsqueeze(dim = 0).float()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter('tensorboard/unet_2d')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instantiate the model and train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "UNet = UNet2D(1, 1, 1).to(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "Epochs = 50\n",
    "df = pd.DataFrame(data = {\"X\": np.arange(1, 10), \"Y\": np.arange(1, 10)})\n",
    "Data_Train = DataLoader(MRI_Dataloader(df), \n",
    "                        batch_size = 9)\n",
    "Optimizer = optim.Adam(UNet.parameters(), lr = 1e-3)\n",
    "for e in range(Epochs):\n",
    "    total_loss = 0\n",
    "    dice_score = 0\n",
    "    for x, y in tqdm_notebook(Data_Train):\n",
    "        x, y = x.to(\"cuda:0\"), y.to(\"cuda:0\")\n",
    "        Optimizer.zero_grad()\n",
    "        y_predicted = F.sigmoid(UNet(x))\n",
    "        Loss_Value = soft_dice_loss(y_predicted, y)\n",
    "        Loss_Value.backward()\n",
    "        Optimizer.step()\n",
    "        total_loss = total_loss + Loss_Value.item()\n",
    "        dice_score = dice_score + dice_metric(y.detach().cpu().numpy(), y_predicted.detach().cpu().numpy())\n",
    "    total_loss = total_loss/df.shape[0]\n",
    "    dice_score = dice_score\n",
    "    #saving metrics\n",
    "    writer.add_scalar('Training loss', total_loss, e)\n",
    "    writer.add_scalar('Training dice score', dice_score, e)\n",
    "    #saving model weights distribution\n",
    "    writer.add_histogram(\"Encoder_1.Conv1.weights\", UNet.Encoder_1[0].weight, e)\n",
    "    writer.add_histogram(\"Encoder_1.Conv1.weights\", UNet.Encoder_1[3].weight, e)\n",
    "    writer.add_histogram(\"Encoder_2.Conv1.weights\", UNet.Encoder_2[0].weight, e)\n",
    "    writer.add_histogram(\"Encoder_2.Conv1.weights\", UNet.Encoder_2[3].weight, e)\n",
    "    writer.add_histogram(\"Encoder_3.Conv1.weights\", UNet.Encoder_4[0].weight, e)\n",
    "    writer.add_histogram(\"Encoder_3.Conv1.weights\", UNet.Encoder_4[3].weight, e)\n",
    "    writer.add_histogram(\"Encoder_4.Conv1.weights\", UNet.Encoder_4[0].weight, e)\n",
    "    writer.add_histogram(\"Encoder_4.Conv1.weights\", UNet.Encoder_4[3].weight, e)\n",
    "    writer.add_histogram(\"Encoder_5.Conv1.weights\", UNet.Encoder_5[0].weight, e)\n",
    "    writer.add_histogram(\"Encoder_5.Conv1.weights\", UNet.Encoder_5[3].weight, e)\n",
    "    writer.add_histogram(\"Decoder_1.Conv1.weights\", UNet.Decoder_1[0].weight, e)\n",
    "    writer.add_histogram(\"Decoder_1.Conv1.weights\", UNet.Decoder_1[3].weight, e)\n",
    "    writer.add_histogram(\"Decoder_2.Conv1.weights\", UNet.Decoder_2[0].weight, e)\n",
    "    writer.add_histogram(\"Decoder_2.Conv1.weights\", UNet.Decoder_2[3].weight, e)\n",
    "    writer.add_histogram(\"Decoder_3.Conv1.weights\", UNet.Decoder_3[0].weight, e)\n",
    "    writer.add_histogram(\"Decoder_3.Conv1.weights\", UNet.Decoder_3[3].weight, e)\n",
    "    writer.add_histogram(\"Decoder_4.Conv1.weights\", UNet.Decoder_4[0].weight, e)\n",
    "    writer.add_histogram(\"Decoder_4.Conv1.weights\", UNet.Decoder_4[3].weight, e)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save model graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer.add_graph(UNet, x)\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save model inputs and outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_temp = (x - x.min())/(x.max() - x.min())\n",
    "writer.add_image(\"Input data\", x_temp.squeeze(dim = 1)[0], dataformats=\"HW\")\n",
    "writer.add_image(\"Real output\", y.squeeze(dim = 1)[0], dataformats=\"HW\")\n",
    "writer.add_image(\"Predicted output\", y_predicted.detach().squeeze(dim = 1)[0], dataformats=\"HW\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Show model inputs and outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10, 20))\n",
    "for i in range(9):\n",
    "    plt.subplot(9, 3, (3*i + 1))\n",
    "    plt.imshow(x_temp[i, 0].detach().cpu())\n",
    "    plt.axis(\"off\")\n",
    "    plt.subplot(9, 3, (3*i + 2))    \n",
    "    plt.imshow(y[i, 0].detach().cpu())\n",
    "    plt.axis(\"off\")\n",
    "    plt.subplot(9, 3, (3*i + 3))    \n",
    "    plt.imshow(y_predicted[i, 0].detach().cpu())\n",
    "    plt.axis(\"off\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
